{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98d0d05e-2c64-4ba1-927e-d39bbd264452",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import shutil\n",
    "\n",
    "def compress_file(file_path):\n",
    "    compressed_file_path = f\"{file_path}.gz\"\n",
    "    with open(file_path, 'rb') as f_in, gzip.open(compressed_file_path, 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "    print(f\"File compressed to {compressed_file_path}\")\n",
    "    return compressed_file_path\n",
    "\n",
    "# Example usage\n",
    "compress_file(\"/Workspace/Users/lormana@campus.technion.ac.il/course_job_dict.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4024700f-7177-4800-855c-1e6f24809832",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def split_file(file_path, max_chunk_size):\n",
    "    file_size = os.path.getsize(file_path)\n",
    "    chunk_count = file_size // max_chunk_size + (1 if file_size % max_chunk_size > 0 else 0)\n",
    "    \n",
    "    with open(file_path, 'rb') as f:\n",
    "        for i in range(chunk_count):\n",
    "            chunk_data = f.read(max_chunk_size)\n",
    "            with open(f\"{file_path}_part_{i}\", 'wb') as chunk_file:\n",
    "                chunk_file.write(chunk_data)\n",
    "    print(f\"File split into {chunk_count} chunks.\")\n",
    "\n",
    "# Example usage\n",
    "file_path = \"/Workspace/Users/lormana@campus.technion.ac.il/course_job_dict.json\"  # Replace with your file path\n",
    "max_chunk_size = 10_485_760  # 10 MB in bytes\n",
    "\n",
    "split_file(file_path, max_chunk_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3438c465-7b6c-4694-b4a6-f9879db54790",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## pip installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "68b8dcdb-9cd1-4b8e-96b2-979559b01673",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "19923f16-7790-4f90-a03a-b8f47326eee4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install google-cloud-translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "2d2e1ba2-e79c-4809-bd39-ee9594bae0d8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Install the googletrans library\n",
    "%pip install googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "05088826-d980-43ac-9234-202ea12594a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "%pip install --upgrade googletrans==4.0.0-rc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "951d74fb-975b-4ccc-ae4c-ebde27deeabc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install spark-nlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "a3334e26-51ac-4627-9c47-e6a993f0ea6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "285a1623-63ab-4ab0-b3e3-6fa2927f602d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f70aa1d5-557e-4eed-9497-476c7f230745",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install deep-translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a3f6bd1-7bb3-41c5-9ef0-65a8691d1cdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install wordcloud matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0d7716a-57a4-4cdc-a11b-7804cf6a82a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%restart_python or dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e931eccd-c973-4eb0-9cbc-5a84f98118bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd73ee3c-4021-491e-80ed-61e77ea5682b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from pyspark.sql.functions import col, udf\n",
    "\n",
    "from googletrans import Translator\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import textwrap\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d04cc5e-1e4e-48df-9d74-3beeb5ae3c69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Translating the scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b0f95ee-1f44-42ff-bc92-f0aa74d700d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"Job Listings\").getOrCreate()\n",
    "file_path = \"dbfs:/FileStore/tables/lormanat/job_listings_1.json\"\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"job_title\", StringType(), True),\n",
    "    StructField(\"job_description\", StringType(), True),\n",
    "    StructField(\"job_requirements\", StringType(), True)\n",
    "])\n",
    "\n",
    "job_listings_df = spark.read.option(\"multiline\", \"true\").schema(schema).json(file_path)\n",
    "\n",
    "job_listings_df.printSchema()\n",
    "display(job_listings_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16184570-a092-4af1-9fa4-352652ecc727",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "filtered_df = job_listings_df.filter(\n",
    "    col(\"job_title\").rlike(\"(?i)data|דאטה|דאטא\")\n",
    ")\n",
    "\n",
    "display(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d157216a-13f1-4f22-824a-039f00eb752f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%python\n",
    "filtered_df.write.csv(\n",
    "    \"/dbfs/FileStore/tables/lormanat/data_jobs/\",\n",
    "    header=True,\n",
    "    mode=\"overwrite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "19c9a85d-fd0e-47ac-a8f4-5acbc17b974e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(os.listdir(\"/dbfs/FileStore/tables/lormanat/data_jobs/\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd081217-5374-4ff4-874c-d2588fd33d80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "def translate_udf(text):\n",
    "    translator = Translator()\n",
    "    return translator.translate(text, dest='en').text\n",
    "\n",
    "translate = udf(translate_udf, StringType())\n",
    "\n",
    "filtered_df = filtered_df.withColumn('job_title_translated', translate(filtered_df['job_title']))\n",
    "\n",
    "display(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d81b997-6395-4dcd-8714-5718006f7f67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def translate_to_english(text):\n",
    "    if text:\n",
    "        try:\n",
    "            return GoogleTranslator(source=\"auto\", target=\"en\").translate(text)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            return text\n",
    "    return text\n",
    "\n",
    "translate_udf = udf(translate_to_english, StringType())\n",
    "\n",
    "translated_df = filtered_df.withColumn('job_title_translated', translate_udf(filtered_df['job_title'])) \\\n",
    "                           .withColumn('job_description_translated', translate_udf(filtered_df['job_description'])) \\\n",
    "                           .withColumn('job_requirements_translated', translate_udf(filtered_df['job_requirements']))\n",
    "\n",
    "display(translated_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "73f45b63-67ab-4a61-a84a-c8b11ff3a228",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## The translated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65a67895-7612-4b3f-8470-476f9d244f28",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "filterBlob": "{\"filterGroups\":[],\"syncTimestamp\":1738692213998}",
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark_df = spark.read.json(\"dbfs:/FileStore/tables/lormanat/translated_jobs.json\")\n",
    "\n",
    "display(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7113833a-c311-498b-ae3b-49b98f128766",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "job_descriptions = spark_df.select('job_description_translated').rdd.flatMap(lambda x: x).collect()\n",
    "job_requirements = spark_df.select('job_requirements_translated').rdd.flatMap(lambda x: x).collect()\n",
    "job_titles = spark_df.select('job_title_translated').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d4b6250-4e26-4670-aea2-2e8235c48f4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Translating syllabus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bffe00a3-fed3-448e-b256-7c1950ab6046",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_path = '/dbfs/FileStore/tables/lormanat/all_courses.csv'  # Replace with your file path\n",
    "\n",
    "syllabus = pd.read_csv(file_path)\n",
    "\n",
    "syllabus = syllabus.drop(columns=['Unnamed: 0','פקולטה'])\n",
    "\n",
    "syllabus = syllabus.rename(columns={\n",
    "    'מסגרת לימודים': 'study framework',\n",
    "    'סילבוס': 'syllabus',\n",
    "    'שם מקצוע':\"subject's name\"\n",
    "})\n",
    "\n",
    "display(syllabus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ad4e5b3-8341-4b76-ac91-e3956f8b4e58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "columns_to_translate = [['study framework','syllabus',\"subject's name\"]]\n",
    "\n",
    "translator = GoogleTranslator(source='hebrew', target='english')\n",
    "\n",
    "for col in columns_to_translate:\n",
    "    syllabus[col] = syllabus[col].apply(lambda x: translator.translate(x) if isinstance(x, str) else x)\n",
    "\n",
    "output_file_path = 'translated_file.csv' \n",
    "syllabus.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(\"Translation complete. Translated file saved as:\", output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "e935f3c7-385d-4ba4-9d7b-fbeb74ee8743",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(syllabus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d0bff3a-10fc-4281-b5d3-7bd35f47bc0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"PandasToSpark\").getOrCreate()\n",
    "syllabus_spark_df = spark.createDataFrame(syllabus)\n",
    "\n",
    "syllabus_spark_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b4099a9-97a3-43fe-b5e1-a192ed48f222",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "from googletrans import Translator\n",
    "\n",
    "def translate_udf(text):\n",
    "    translator = Translator()\n",
    "    return translator.translate(text, dest='en').text\n",
    "\n",
    "translate = udf(translate_udf, StringType())\n",
    "\n",
    "filtered_df_2 = (\n",
    "    syllabus_spark_df\n",
    "    .withColumn('study_framework_translated', translate(syllabus_spark_df['study framework']))\n",
    "    .withColumn('syllabus_translated', translate(syllabus_spark_df['syllabus']))\n",
    "    .withColumn('subject_name_translated', translate(syllabus_spark_df[\"subject's name\"]))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c61490c-72c2-476e-ad34-0853fa8362ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "syllabus_translated = filtered_df_2.select('study_framework_translated','syllabus_translated','subject_name_translated')\n",
    "display(syllabus_translated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9215feec-6bcf-449e-be67-a4286d92478e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Translated syllabus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bda9d304-69cd-4992-ac99-aea2d2f351ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_pandas = pd.read_csv('/dbfs/FileStore/tables/lormanat/syllabus_translated.csv')\n",
    "\n",
    "translated_syllabus = spark.createDataFrame(df_pandas)\n",
    "\n",
    "display(translated_syllabus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a973f34-634d-4e55-85ee-f5824f0cce80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "courses = translated_syllabus.select('subject_name_translated').rdd.flatMap(lambda x: x).collect()\n",
    "syllabuses = translated_syllabus.select('syllabus_translated').rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2279e59-7d38-4d88-a8bc-800e5ef303c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "49368d98-b4b0-4406-a14d-80b082598482",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sbert_model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51cf828d-d75b-4237-9505-99c3c97d1761",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "example_syllabus = \"\"\"Advanced methods for analyzing data and incorporating statistical tools and machine learning tools for data analysis, visually presenting them and building classification and prediction systems.Among the topics in the course will be taught: prediction and linear aggression, classification systems, Enihcam, Gnilpmaser, CAP, Rotcev Troppus, selection of models and vagulasis, decision trees and aggression, cluster analysis.Learning results: Theoretical understanding of the various methods and implementation of real data.\"\"\"\n",
    "example_syllabus_embeddings = sbert_model.encode([example_syllabus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07751459-4607-44e9-8f9d-16e3c4452497",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def cosine(u, v):\n",
    "    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d4af9cf3-a69d-45b5-b9e6-bacc141e8713",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "listing_embeddings = [sbert_model.encode(job_description) for job_description in job_requirements[:5]]\n",
    "course_ranking = {}\n",
    "for course, syllabus in zip(courses, syllabuses):\n",
    "    course_ranking[course] = sum([cosine(listing_embedding, sbert_model.encode([syllabus])[0]) for listing_embedding in listing_embeddings])/5\n",
    "\n",
    "sorted_courses = sorted(course_ranking, key=course_ranking.get, reverse=True)\n",
    "print(sorted_courses[:10])\n",
    "print(sorted_courses[-10:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed8b9f2d-3e94-4638-b712-e739a417fe57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "course_job_dict = {}\n",
    "for course, syllabus in zip(courses, syllabuses):\n",
    "    course_job_dict[course] = {}\n",
    "    syllabus_embedding = sbert_model.encode([syllabus])[0]\n",
    "    for job_title, job_requirement in zip(job_titles, job_requirements):\n",
    "        if job_requirement is None:\n",
    "            continue\n",
    "        course_job_dict[course][job_title] = float(cosine(syllabus_embedding, sbert_model.encode([job_requirement])[0]))\n",
    "#save dict to json\n",
    "import json\n",
    "with open('course_job_dict.json', 'w') as f:\n",
    "    json.dump(course_job_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cd768a3-59f7-4556-b012-f477d851a8d7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "selected_jobs = {}\n",
    "for i, (job_description, job_title) in enumerate(zip(job_requirements, job_titles)):\n",
    "    if job_description is None:\n",
    "        continue\n",
    "    if not i%100:\n",
    "        print(i)\n",
    "    sim = cosine(example_syllabus_embeddings, sbert_model.encode([job_description])[0])\n",
    "    selected_jobs[(i, job_title)] = sim[0]\n",
    "print({k: v for k, v in sorted(selected_jobs.items(), key=lambda item: item[1], reverse=True)[:10]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c1a2cd1a-a088-496d-b9e9-d26472443a17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Courses from udemi and coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cce776b-2ff3-446a-8955-42fdcfe0f15d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "udemy_df = pd.read_csv('udemy.csv', encoding='ISO-8859-1')\n",
    "coursera_df = pd.read_csv('coursera_courses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc092d6f-0cae-4156-b841-025464b7ef54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "udemy_relevant_df = udemy_df[['name', 'description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fe16b05-b67d-40dc-b14c-54b257ed1543",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "udemy_relevant_df.columns = ['course', 'summary']\n",
    "udemy_relevant_df['source'] = 'udemy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99c3c390-99d0-4deb-ba25-820387c9ac6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "coursera_relevant_df = coursera_df[['course_title', 'course_description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b441ace-15cc-478c-bdab-ccf273b7c531",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "coursera_relevant_df.columns = ['course', 'summary']\n",
    "coursera_relevant_df['source'] = 'coursera'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b10d09a0-38ea-4347-9438-3c9efc9cb80b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Merged df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7469af7-eb86-467a-ab46-a76c9f9f6047",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "technion_relevant_df = translated_syllabus.toPandas()[['syllabus_translated', 'subject_name_translated']]\n",
    "technion_relevant_df.columns = ['summary', 'course']\n",
    "technion_relevant_df['source'] = 'technion'\n",
    "technion_relevant_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73530afa-f403-4730-8637-57f6f5c3273f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "merged_df = pd.concat([udemy_relevant_df, coursera_relevant_df, technion_relevant_df])\n",
    "merged_df.head()\n",
    "print(merged_df.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce536caa-a586-4f5f-9a0b-87300388dac4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "courses = list(merged_df['course'])\n",
    "syllabuses = list(merged_df['summary'])\n",
    "sources = list(merged_df['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4579e754-e7cd-4ff0-98b3-a6f415efe4c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "example_listing = \"\"\"- Master's or PhD in Computer Science or related field\n",
    "- Familiarity with Machine Learning algorithms\n",
    "- Experience working as a Data Scientist for a product company\n",
    "- Familiarity with Python/ Pandas\n",
    "- Familiarity with Deep Learning algorithms on the following platforms: Tensorflow, Keras, Theano, CNTK, PyTorch\"\"\"\n",
    "example_listing_embeddings = sbert_model.encode([example_listing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "016fb02b-f5e7-47bb-84c6-740a1c9c28e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "course_embeddings = [sbert_model.encode(str(summary)) for summary in syllabuses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd00779a-f09c-4add-a58e-f0838708f8c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "course_ranking = {}\n",
    "for i, (course, embedding, source) in enumerate(zip(courses, course_embeddings, sources)):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    course_ranking[(course, source)] = np.dot(example_listing_embeddings, embedding)\n",
    "\n",
    "sorted_courses = sorted(course_ranking, key=course_ranking.get, reverse=True)\n",
    "print(sorted_courses[:10])\n",
    "print(sorted_courses[-10:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7fba7356-e076-40aa-a5ca-5b7a77c1781d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### NLP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7352dc47-79d1-4381-832b-52456f704919",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b6ef8199-82cc-483e-bc5c-625fc819d5a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower() \n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    return [word for word in words if word not in stop_words]\n",
    "\n",
    "def lemmatize(words):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(word) for word in words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6cf17158-0330-489c-aa28-f984be406d70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Job listings' table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ce6e73a-216a-4657-a0b9-26b8eda73805",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pandas_job_df = spark_df.toPandas()\n",
    "pandas_job_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69f66c9f-0781-4d1f-b3ec-a950149c15f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pandas_job_df[\"cleaned_text\"] = pandas_job_df[\"job_description_translated\"].apply(clean_text)\n",
    "pandas_job_df[\"tokens\"] = pandas_job_df[\"cleaned_text\"].apply(tokenize)\n",
    "pandas_job_df[\"filtered_tokens\"] = pandas_job_df[\"tokens\"].apply(remove_stopwords)\n",
    "pandas_job_df[\"lemmatized_tokens\"] = pandas_job_df[\"filtered_tokens\"].apply(lemmatize)\n",
    "pandas_job_df[\"processed_text\"] = pandas_job_df[\"lemmatized_tokens\"].apply(lambda x: ' '.join(x))\n",
    "\n",
    "pandas_job_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f274799-96ad-4b10-89e8-fb6e221b8835",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Courses' table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05bc677e-8ca8-4988-93af-207fdc950dd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    else:\n",
    "        text = ''\n",
    "    return text\n",
    "\n",
    "merged_df[\"cleaned_text\"] = merged_df['summary'].apply(clean_text)\n",
    "merged_df[\"tokens\"] = merged_df[\"cleaned_text\"].apply(tokenize)\n",
    "merged_df[\"filtered_tokens\"] = merged_df[\"tokens\"].apply(remove_stopwords)\n",
    "merged_df[\"lemmatized_tokens\"] = merged_df[\"filtered_tokens\"].apply(lemmatize)\n",
    "merged_df[\"processed_text\"] = merged_df[\"lemmatized_tokens\"].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "595b5108-7331-4c74-a406-27428a75782d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Job titles we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5b0ddb86-9fd0-4f7d-a4c4-ee804ce923a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pandas_job_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f886e5e1-7cd5-4487-86ad-122b89dbc622",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Clustering Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d174354-0ced-43be-bbb7-c0d038cf6531",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "syllabus_embeddings = sbert_model.encode([str(syllabus) for syllabus in syllabuses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92012018-d13b-427a-986b-bf11404cbd82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_word_cloud(listings_input, title=None, removed_words=None, top_n=100):\n",
    "    listing_embeddings = sbert_model.encode(listings_input)\n",
    "    course_ranking = {}\n",
    "    for course, syllabus_embedding in zip(courses, syllabus_embeddings):\n",
    "        similarities = [cosine(listing_embedding, syllabus_embedding) for listing_embedding in listing_embeddings]\n",
    "        course_ranking[course] = sum(similarities)\n",
    "\n",
    "    course_ranking_list = course_ranking.tolist() if hasattr(course_ranking, 'tolist') else course_ranking\n",
    "    sorted_courses_job = sorted(course_ranking_list, key=course_ranking.get, reverse=True)\n",
    "\n",
    "    sorted_courses_job_str = ' '.join(sorted_courses_job[:top_n])\n",
    "\n",
    "    if removed_words:\n",
    "        sorted_courses_job_str = re.sub('('+r')|('.join(removed_words)+')', '', sorted_courses_job_str)\n",
    "\n",
    "    wordcloud = WordCloud(\n",
    "        width=800,\n",
    "        height=400,\n",
    "        background_color='white',\n",
    "        colormap='viridis'\n",
    "    ).generate(sorted_courses_job_str)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')  \n",
    "    plt.title(f\"{title if title else 'Word Cloud'}\", fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e46c8ea0-0a7c-4e3c-853e-0f828c4507b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Clustering by Job Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68ab9797-3f90-42d2-954a-a8a563e51370",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "job_requirements = pandas_job_df[\"job_requirements_translated\"].fillna(\"\") \n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "X = vectorizer.fit_transform(job_requirements)  \n",
    "\n",
    "range_n_clusters = range(2, 15)  \n",
    "inertia_scores = []  \n",
    "silhouette_scores = []  \n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    clusters = kmeans.fit_predict(X)\n",
    "    \n",
    "    inertia_scores.append(kmeans.inertia_)\n",
    "    \n",
    "    if n_clusters > 1:\n",
    "        silhouette_avg = silhouette_score(X, clusters)\n",
    "        silhouette_scores.append(silhouette_avg)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range_n_clusters, inertia_scores, marker='o', label=\"Inertia (SSE)\")\n",
    "plt.title(\"Elbow Method: Optimal Number of Clusters\")\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Inertia (SSE)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(2, 15), silhouette_scores, marker='o', label=\"Silhouette Score\", color=\"orange\")\n",
    "plt.title(\"Silhouette Scores: Optimal Number of Clusters\")\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bc022264-a693-4fb0-9e80-4d3be926e99d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "pandas_job_df[\"job_requirements_translated\"] = pandas_job_df[\"job_requirements_translated\"].fillna(\"\")\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "X = vectorizer.fit_transform(pandas_job_df[\"job_requirements_translated\"])\n",
    "\n",
    "n_clusters = 6  \n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "pandas_job_df[\"cluster\"] = kmeans.fit_predict(X)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "reduced_data = pca.fit_transform(X.toarray())\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(n_clusters):\n",
    "    points = reduced_data[pandas_job_df[\"cluster\"] == i]\n",
    "    plt.scatter(points[:, 0], points[:, 1], label=f\"Cluster {i}\")\n",
    "\n",
    "plt.title(\"Job requirements Clusters\")\n",
    "plt.xlabel(\"PCA Component 1\")\n",
    "plt.ylabel(\"PCA Component 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95ea0637-e896-45cf-9040-98b17cf0bc2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cluster_counts = pandas_job_df['cluster'].value_counts()\n",
    "\n",
    "print(cluster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e52ac3b2-2aac-4b3c-bfe2-c66242962692",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "grouped_clusters = pandas_job_df.groupby('cluster')\n",
    "\n",
    "for cluster, group in grouped_clusters:\n",
    "    print(f\"Cluster {cluster}:\")\n",
    "    print(group['job_title_translated'].sample(n=5, random_state=42, replace=True)) \n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "280f32a2-b39f-4490-b22b-2180ee9e5ee9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "random_job_requirements_2 = [list(pandas_job_df[pandas_job_df['cluster'] == i]['job_requirements_translated'].loc[pandas_job_df[pandas_job_df['cluster'] == i]['job_title_translated'].sample(n=10, random_state=42, replace=True).index]) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74c1a358-79cc-4fd8-9d71-9eef69435e5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for i in range(6):\n",
    "    if i not in [0, 4]:\n",
    "        continue\n",
    "    generate_word_cloud(\n",
    "        random_job_requirements_2[i], \n",
    "        title=\"Cloud Engineering Cluster's Courses\" if i == 0 else (\"SQL Bootcamp Cluster's Courses\" if i == 4 else f\"Cluster {i}'s Courses\"), \n",
    "        removed_words=['IBM', 'Python', 'Data Science', 'Data', 'Machine Learning', 'Fundamentals', 'Google Cloud'],\n",
    "        top_n=50\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7584052a-0331-4ac8-b00d-d690b8febe7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Proof of Concept - feature demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90a4aa6a-9a5a-4b02-909a-a1722ced4aef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "listings = [ ('Data Scientist for a start up in the cyber world ', \"\"\"- Master's or PhD in Computer Science or related field\n",
    "- Familiarity with Machine Learning algorithms\n",
    "- Experience working as a Data Scientist for a product company\n",
    "- Familiarity with Python/ Pandas\n",
    "- Familiarity with Deep Learning algorithms on the following platforms: Tensorflow, Keras, Theano, CNTK, PyTorch\"\"\"),\n",
    "('Junior data engineer at a tech company', \"\"\"-3 years of experience in Java/Scala development\n",
    "-Experience in Big Data technologies\n",
    "-Spark\n",
    "-Mastery of big data - Kinesis / Kafka / Cassandra / Solr\n",
    "-Good at data engineering\n",
    "-Experience with data visualization tools\n",
    "-Experience with sklearn, numpy, pandas\n",
    "-Experience with machine learning\n",
    "-Experience with deep learning\n",
    "-Experience with big data\n",
    "-Experience with reinforcement learning\n",
    "-Experience with pytorch pyspark nlp\n",
    "\"\"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15de6452-40d4-4093-95ad-c7db6b3a4a46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(spark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "231e86b3-7339-4c20-8c1f-a835867e10c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "listings = [('Java big data',\"\"\"At least 4 years of experience in Java development.\n",
    "Experience in team management.\n",
    "Experience in architecture and development from Scratch.\n",
    "Experience working with NOSQL databases.\n",
    "Experience in Big Data technologies.\n",
    "B.sc/ BA in Computer Science/ Software Engineering.\"\"\"),('Full Stack Software Engineer for a company dealing with the world of data in Herzliya',\"\"\"- 5 years of experience with NodeJS\n",
    "- 4 years of experience with React or Vue\n",
    "- Familiarity with Docker\n",
    "- Familiarity with one of the following technologies: MongoDB/Elasticsearch/RabbitMQ/kafka\"\"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3bdd605-d7c7-4301-b0c1-92699eb07550",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "max_chars_per_line = 35\n",
    "def show_relevant_courses(listings):\n",
    "    job_titles = [listing[0] for listing in listings]\n",
    "    requirements = [listing[1] for listing in listings]\n",
    "    requirements_embeddings = sbert_model.encode(requirements)\n",
    "    similarities = {}\n",
    "    for course, course_embedding, source in zip(courses, course_embeddings, sources):\n",
    "        similarities[(course, source)] = (sum([cosine(course_embedding, job_embedding) for job_embedding in requirements_embeddings])/len(requirements), course_embedding)\n",
    "\n",
    "    relevant_courses = sorted(similarities, key=lambda x: similarities[x][0], reverse=True)[:5]\n",
    "    edges = []\n",
    "    for i, (job, job_embedding) in enumerate(zip(job_titles, requirements_embeddings)):\n",
    "        for j, (course, source) in enumerate(relevant_courses):\n",
    "            edges.append((job, course, source, cosine(similarities[(course, source)][1], job_embedding)))\n",
    "\n",
    "    fig = go.Figure()\n",
    "    deafult_width = 1.2\n",
    "    def add_rectangle(fig, x, y, text, width=deafult_width, height=0.4, color=\"blue\", hovertext=None):\n",
    "        text = \"<br>\".join(textwrap.wrap(text, width=max_chars_per_line, break_long_words=False))\n",
    "        rect_x = [x - width/2, x + width/2, x + width/2, x - width/2, x - width/2]\n",
    "        rect_y = [y - height/2, y - height/2, y + height/2, y + height/2, y - height/2]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=rect_x, y=rect_y,\n",
    "            fill=\"toself\",\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=color),\n",
    "            fillcolor=color,\n",
    "            hoverinfo=\"none\"\n",
    "        ))\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[x], y=[y],\n",
    "            mode=\"text+markers\",\n",
    "            text=[text],\n",
    "            textfont=dict(size=12, color=\"white\"),\n",
    "            hoverinfo=\"text\" if hovertext else \"none\",\n",
    "            hovertext=hovertext,\n",
    "            marker=dict(opacity=0)\n",
    "        ))\n",
    "\n",
    "    # Add job nodes (left side)\n",
    "    for i, (job, requirements) in enumerate(listings):\n",
    "        add_rectangle(\n",
    "            fig, x=-1, y=2*i + 1, text=job, color=\"rgb(58, 232, 161)\",\n",
    "            hovertext=\"<br>\".join(requirements.split('-'))\n",
    "        )\n",
    "\n",
    "    source_to_color = {'technion': 'green', 'udemy': \"rgb(164, 53, 240)\", 'coursera': \"rgb(0, 86, 210)\"}\n",
    "    # Add course nodes (right side)\n",
    "    for i, (course, source) in enumerate(relevant_courses):\n",
    "        add_rectangle(\n",
    "            fig, x=1, y=4-i, text=course, color=source_to_color[source],\n",
    "                            hovertext=f\"Source: {source}\"\n",
    "                            )\n",
    "\n",
    "    max_sim = max(sim for _, _, _, sim in edges)\n",
    "    min_sim = min(sim for _, _, _, sim in edges)\n",
    "    edges = [(job, course, source, 1/2+(sim - min_sim)/(max_sim-min_sim)/2) for job, course, source, sim in edges if sim > 0.5]\n",
    "\n",
    "    # Add edges\n",
    "    for job, course, source, sim in edges:\n",
    "        dissim = 1 - sim\n",
    "        color = f\"rgb({dissim*255}, {dissim*255}, {dissim*255})\"\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=[-1+deafult_width/2, 1-deafult_width/2],\n",
    "            y=[job_titles.index(job)*2 + 1, 4-[name for name, sour in relevant_courses].index(course)],\n",
    "            mode=\"lines\",\n",
    "            line=dict(width=5, color=color)\n",
    "        ))\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        showlegend=False,\n",
    "        xaxis=dict(showgrid=False, zeroline=False, visible=False),\n",
    "        yaxis=dict(showgrid=False, zeroline=False, visible=False),\n",
    "        margin=dict(l=100, r=100, t=50, b=50),\n",
    "        plot_bgcolor=\"white\",\n",
    "        height=600,\n",
    "        hoverlabel=dict(\n",
    "            bgcolor=\"white\",  # Background color\n",
    "            font_size=12,     # Font size\n",
    "            font_family=\"Arial\"  # Font family\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Display the figure\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "659cea08-e513-49b0-b45d-b73af94c9dbe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "show_relevant_courses(listings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83b8fc68-f9c2-4e08-b357-d532c1a777ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4,
    "widgetLayout": []
   },
   "notebookName": "syllabus_project 2025-01-22 13:58:36",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}